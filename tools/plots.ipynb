{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visual Demonstration\n",
    "\n",
    "After TTA with 4 times, this notebook simply visually demonstrate the progress of each tta step result with the final tta results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob, pprint, zipfile, os\n",
    "from tta_utils import *\n",
    "import plotly.figure_factory as ff\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# with zipfile.ZipFile(path_to_zip_file, 'r') as zip_ref:\n",
    "#     zip_ref.extractall(directory_to_extract_to)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Images and Text Annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root    = './MaskTextSpotterV3'\n",
    "folders = [f for f in sorted(os.listdir('./out_images/'))]\n",
    "folder  = np.random.choice(folders)\n",
    "\n",
    "labels = [gt for gt in sorted(glob.glob(root + f'/tools/out_text/{folder}/*.txt'))]\n",
    "images = [cv2.imread(img) for img in sorted(glob.glob(root + f'/tools/out_images/{folder}/*.jpg'))]\n",
    "\n",
    "len(labels), len(images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess the Annotation File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_one, xx, yy, cts_one, scores_one = get_cords(labels[0], data = [], \n",
    "                                              xx = [], yy = [], cts = [], scores = [])\n",
    "data_two, xx, yy, cts_two, scores_two = get_cords(labels[1], data = [], \n",
    "                                              xx = [], yy = [], cts = [], scores = [])\n",
    "data_thr, xx, yy, cts_thr, scores_thr = get_cords(labels[2], data = [], \n",
    "                                              xx = [], yy = [], cts = [], scores = [])\n",
    "data_fur, xx, yy, cts_fur, scores_fur = get_cords(labels[3], data = [], \n",
    "                                                  xx = [], yy = [], cts = [], scores = [])\n",
    "data_fiv, xx, yy, cts_fiv, scores_fiv = get_cords(labels[4], data = [], \n",
    "                                                  xx = [], yy = [], cts = [], scores = [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(zip(scores_one, cts_one))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparision Chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(go.Bar(\n",
    "    x=cts_one,\n",
    "    y=scores_one,\n",
    "    name='1.txt',\n",
    "    marker_color='#A6ACEC'\n",
    "))\n",
    "\n",
    "fig.add_trace(go.Bar(\n",
    "    x=cts_two,\n",
    "    y=scores_two,\n",
    "    name='2.txt',\n",
    "    marker_color='#63F5EF'\n",
    "))\n",
    "\n",
    "fig.add_trace(go.Bar(\n",
    "    x=cts_thr,\n",
    "    y=scores_thr,\n",
    "    name='3.txt',\n",
    "    marker_color='#A56CC1'\n",
    "))\n",
    "\n",
    "fig.add_trace(go.Bar(\n",
    "    x=cts_fur,\n",
    "    y=scores_fur,\n",
    "    name='4.txt',\n",
    "    marker_color='#63CCF5'\n",
    "))\n",
    "\n",
    "fig.add_trace(go.Bar(\n",
    "    x=cts_fiv,\n",
    "    y=scores_fiv,\n",
    "    name='result.txt',\n",
    "    marker_color='#F56379'\n",
    "))\n",
    "\n",
    "# Here we modify the tickangle of the xaxis, resulting in rotated labels.\n",
    "fig.update_layout(barmode='group', xaxis_tickangle=-45)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vis_polygons(image, polygons, words):\n",
    "    '''\n",
    "    It will plot polygons with connected keypoints (poly-lines) with transcriptions\n",
    "    '''\n",
    "    fig, ax =plt.subplots(ncols=1, nrows=1, constrained_layout=True, figsize=(15,15))\n",
    "    for polygon, word in zip(polygons, words):\n",
    "        pts = np.array(polygon, np.int32)\n",
    "        pts = pts.reshape((-1,1,2))\n",
    "        xmin = min(pts[:,0,0])\n",
    "        ymin = min(pts[:,0,1])\n",
    "        cv2.polylines(image,[pts],True,(0,255,0), 2)\n",
    "        cv2.putText(image, word, (xmin, ymin), cv2.FONT_HERSHEY_COMPLEX, 1, (199, 12, 90), 2)\n",
    "    ax.imshow(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint.pprint(list(zip(cts_two, scores_two)))\n",
    "vis_polygons(images[1], data_two, cts_two)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(os.listdir('./out_text/'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(os.listdir('./out_images/'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(os.listdir('./out_json/'))"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "pytorch-gpu.1-4.m48",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-4:m48"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
